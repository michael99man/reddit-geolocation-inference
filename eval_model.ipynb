{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from  gensim.models import KeyedVectors\n",
    "from featurization import word2vec, featurizer\n",
    "import model as m\n",
    "from featurizer import ChungusSet \n",
    "from torch.utils.data import DataLoader\n",
    "import geopy\n",
    "from geopy.distance import geodesic\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01:45:32: loading projection weights from ./models/word2vec.model\n",
      "INFO - 01:46:10: loaded (126352, 300) matrix from ./models/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# load word embeddings\n",
    "def load_embedding():\n",
    "    # load word2vec weights\n",
    "    EpochSaver = word2vec.EpochSaver\n",
    "    w2v = KeyedVectors.load_word2vec_format('./models/word2vec.model')\n",
    "\n",
    "    weights = torch.FloatTensor(w2v.vectors)\n",
    "    embedding = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "embedding = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "path = \"epoch_74.model\"\n",
    "model = m.Classifier(embedding)\n",
    "model = nn.DataParallel(model, device_ids=[0,1,2,3,4,5,6,7])\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(\"cuda:0\")\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    test_set = pickle.load(open(\"data/test_set.p\", \"rb\"))\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True,num_workers=30, drop_last=True)\n",
    "    print(\"Test set of %d entries\" % len(test_set))\n",
    "    err=0\n",
    "    tot = 0\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for (words, subs, times, labels) in test_loader:\n",
    "            # remove subs, see how model does\n",
    "            # subs = torch.zeros(batch_size, 5000)   \n",
    "            \n",
    "            output = model(words, subs, times, labels)\n",
    "        \n",
    "            # let the maximum index be our predicted class\n",
    "            _, yh = torch.max(output, 1)\n",
    "\n",
    "            tot += labels.size(0)\n",
    "            \n",
    "            i+=1\n",
    "            if(i % 10 == 0):\n",
    "                print(\"Iteration: %d, processed %d labels\" % (i, tot))\n",
    "                print(labels.size())\n",
    "            \n",
    "            ## add to err number of missclassification, i.e. number of indices that\n",
    "            ## yh and y are not equal\n",
    "            ## note that y and yh are vectors of size = batch_size = (256 in our case)\n",
    "            err += sum(list(map(lambda i: 1 if labels[i] != yh[i] else 0, range(len(labels)))))\n",
    "\n",
    "    print('Accuracy of FC prediction on test users: %5.2f%%' % (100-100 * err / tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set of 10755 entries\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8f8da44c3ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 70: 59.54\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 73: 58.71\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "# 55: 57.99\n",
    "# 58: 58.18\n",
    "# 60: 58.28\n",
    "# 69: 58.80%\n",
    "# 70: 59.54\n",
    "# 73: 58.71\n",
    "\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
